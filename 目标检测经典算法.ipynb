{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset,metadata = tfds.load('fashion_mnist',as_supervised=True,with_info=True)\n",
    "print(metadata)\n",
    "train_dataset,test_dataset = dataset['train'],dataset['test']\n",
    "train_dataset = train_dataset.shuffle(100).batch(12).repeat()\n",
    "\n",
    "for img,label in train_dataset.take(1):\n",
    "    img = img.numpy()\n",
    "    print(img.shape)\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(24).reshape(2,3,4).transpose(1,2,0)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择性搜索算法-select search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Region Proposals: 7049\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    " \n",
    "# 读取照片，这里要根据具体情况设置路径\n",
    "im = cv2.imread(\"./dog_cat.jpg\")\n",
    "\n",
    "# 重置图片大小，高设置为 400，保持高、宽比例\n",
    "newHeight = 400\n",
    "newWidth = int(im.shape[1]*400/im.shape[0])\n",
    "im = cv2.resize(im, (newWidth, newHeight))    \n",
    "\n",
    "# 创建 Selective Search Segmentation 对象\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# 添加待处理的图片\n",
    "ss.setBaseImage(im)\n",
    "\n",
    "# 可以选择快速但是低 recall 的方式 \n",
    "# 这里的 recall 指的是选择出来的 region 是否包含了所有应该包含的区域。recall 越高越好\n",
    "#ss.switchToSelectiveSearchFast()\n",
    "\n",
    "# 也可以选择慢速但是高 recall 的方式\n",
    "ss.switchToSelectiveSearchQuality()\n",
    "\n",
    "\n",
    "# 进行 region 划分，输出得到的 region 数目\n",
    "rects = ss.process()\n",
    "print('Total Number of Region Proposals: {}'.format(len(rects)))\n",
    "\n",
    "# 设定要显示的 region 数目\n",
    "numShowRects = 100\n",
    "\n",
    "# 可以通过按键逐步增加或者减少显示的 region 数目\n",
    "increment = 10\n",
    "\n",
    "while True:\n",
    "    # 不要在原图上画 bounding box，而是复制一个新图\n",
    "    imOut = im.copy()\n",
    "\n",
    "    # 遍历 regions\n",
    "    for i, rect in enumerate(rects):\n",
    "        # 通过 bounding box 显示出指定数量的 region\n",
    "        if (i < numShowRects):\n",
    "            x, y, w, h = rect  # bounding box 左上角坐标 x,y, 以及 box 的宽和高\n",
    "            cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1) # 绿色 box，线宽为 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # 显示图片+bbox\n",
    "    cv2.imshow(\"Output\", imOut)\n",
    "\n",
    "    # 接收按键输入\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # “m” 键 is pressed\n",
    "    if k == 109:\n",
    "        # 增加显示的 bbox 数目\n",
    "        numShowRects += increment\n",
    "    # “l” 键 is pressed\n",
    "    elif k == 108 and numShowRects > increment:\n",
    "        # 减少显示的 bbox 数目\n",
    "        numShowRects -= increment\n",
    "    # “q” 键 is pressed\n",
    "    elif k == 113:  \n",
    "        break\n",
    "# close image show window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于opencv+keras和yolo2的车道检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darknet19 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,LeakyReLU,BatchNormalization\n",
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from ..utils import compose\n",
    "\n",
    "_DarknetConv2D = partial(Conv2D,padding='same')\n",
    "\n",
    "@functool.wraps(Conv2D)\n",
    "def DarknetConv2D(*args,**kwargs):\n",
    "    \"\"\"Wrapper to set Darknet weight regularizer for Convolution2D\"\"\"\n",
    "    darknet_conv_kwargs = {'kernel_regularizer':l2(5e-4)}\n",
    "    darkent_conv_kwargs.update(kwargs)\n",
    "    return _DarknetConv2D(*args,**darknet_conv_kwargs)\n",
    "\n",
    "def DarknetConv2D_BN_Leaky(*args,**kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU\"\"\"\n",
    "    no_bias_kwargs = {'use_bias':False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args,**no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "def bottleneck_block(outer_filters,bottleneck_filters):\n",
    "    \"\"\"Bottleneck block of 3x3,1x1,3x3 convolutions.\"\"\"\n",
    "    return compose(\n",
    "        DarknetConv2D_BN_Leaky(outer_filters,(3,3)),\n",
    "        DarknetConv2D_BN_Leaky(bottleneck_filters,(1,1)),\n",
    "        DarknetConv2D_BN_Leaky(outer_filters,(3,3)))\n",
    "\n",
    "def bottleneck_x2_block(outer_filters,bottleneck_filters):\n",
    "    \"\"\"Bottleneck block of 3x3,1x1,3x3,1x1,3x3 convolutions.\"\"\"\n",
    "    return compose(\n",
    "        bottleneck_block(outer_filters,bottleneck_filters),\n",
    "        DarknetConv2D_BN_Leaky(bottleneck_filters,(1,1)),\n",
    "        DarknetConv2D_BN_Leaky(outer_filters,(3,3)))\n",
    "\n",
    "def darkent_body():\n",
    "    \"\"\"Generate first 18 conv layers of Darknet-19\"\"\"\n",
    "    return compose(\n",
    "        #Input(shape=())\n",
    "        DarknetConv2D_BN_Leaky(32,(3,3)),\n",
    "        MaxPool2D(),\n",
    "        DarknetConv2D_BN_Leaky(64,(3,3)),\n",
    "        MaxPool2D(),\n",
    "        bottleneck_block(128,64),\n",
    "        MaxPool2D(),\n",
    "        bottleneck_block(256,128),\n",
    "        MaxPool2D(),\n",
    "        bottleneck_x2_block(512,256),\n",
    "        MaxPool2D(),\n",
    "        bottleneck_x2_block(1024,512))\n",
    "\n",
    "def darknet19(inputs):\n",
    "    \"\"\"Generate Darknet-19 model for Imagenet classification\"\"\"\n",
    "    body = darknet_body()(inputs)\n",
    "    logits = DarknetConv2D(1000,(1,1),activation='softmax')(body)\n",
    "    return Model(inputs,logits)\n",
    "\n",
    "\n",
    "model = darknet19()\n",
    "model.load_model()\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics='accuracy')\n",
    "\n",
    "loss,accuracy = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目标检测YOLOv2-小白将"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/coco_classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-adcd90006b1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_coco_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-adcd90006b1a>\u001b[0m in \u001b[0;36mread_coco_labels\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_coco_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/coco_classes.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/coco_classes.txt'"
     ]
    }
   ],
   "source": [
    "#cofig.py\n",
    "\"\"\"\n",
    "Yolov2 anchors and coco classes\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "anchors = [[0.738768, 0.874946],\n",
    "           [2.42204, 2.65704],\n",
    "           [4.30971, 7.04493],\n",
    "           [10.246, 4.59428],\n",
    "           [12.6868, 11.8741]]\n",
    "\"\"\"\n",
    "anchors = [[0.57273, 0.677385],\n",
    "           [1.87446, 2.06253],\n",
    "           [3.33843, 5.47434],\n",
    "           [7.88282, 3.52778],\n",
    "           [9.77052, 9.16828]]\n",
    "\n",
    "def read_coco_labels():\n",
    "    f = open(\"./data/coco_classes.txt\")\n",
    "    class_names = []\n",
    "    for l in f.readlines():\n",
    "        class_names.append(l[:-1])\n",
    "    return class_names\n",
    "\n",
    "class_names = read_coco_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo.py\n",
    "\"\"\"\n",
    "Demo for yolov2\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from model import darknet\n",
    "from detect_ops import decode\n",
    "from utils import preprocess_image, postprocess, draw_detection\n",
    "from config import anchors, class_names\n",
    "\n",
    "\n",
    "input_size = (416, 416)\n",
    "image_file = \"./images/car.jpg\"\n",
    "image = cv2.imread(image_file)\n",
    "image_shape = image.shape[:2]\n",
    "image_cp = preprocess_image(image, input_size)\n",
    "\"\"\"\n",
    "image = Image.open(image_file)\n",
    "image_cp = image.resize(input_size, Image.BICUBIC)\n",
    "image_cp = np.array(image_cp, dtype=np.float32)/255.0\n",
    "image_cp = np.expand_dims(image_cp, 0)\n",
    "#print(image_cp)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "images = tf.placeholder(tf.float32, [1, input_size[0], input_size[1], 3])\n",
    "detection_feat = darknet(images)\n",
    "feat_sizes = input_size[0] // 32, input_size[1] // 32\n",
    "detection_results = decode(detection_feat, feat_sizes, len(class_names), anchors)\n",
    "\n",
    "checkpoint_path = \"./checkpoint_dir/yolo2_coco.ckpt\"\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    bboxes, obj_probs, class_probs = sess.run(detection_results, feed_dict={images: image_cp})\n",
    "\n",
    "bboxes, scores, class_inds = postprocess(bboxes, obj_probs, class_probs,\n",
    "                                         image_shape=image_shape)\n",
    "img_detection = draw_detection(image, bboxes, scores, class_inds, class_names)\n",
    "cv2.imwrite(\"detection.jpg\", img_detection)\n",
    "cv2.imshow(\"detection results\", img_detection)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detection ops for Yolov2\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def decode(detection_feat, feat_sizes=(13, 13), num_classes=80,\n",
    "           anchors=None):\n",
    "    \"\"\"decode from the detection feature\"\"\"\n",
    "    H, W = feat_sizes\n",
    "    num_anchors = len(anchors)\n",
    "    detetion_results = tf.reshape(detection_feat, [-1, H * W, num_anchors,\n",
    "                                        num_classes + 5])\n",
    "\n",
    "    bbox_xy = tf.nn.sigmoid(detetion_results[:, :, :, 0:2])\n",
    "    bbox_wh = tf.exp(detetion_results[:, :, :, 2:4])\n",
    "    obj_probs = tf.nn.sigmoid(detetion_results[:, :, :, 4])\n",
    "    class_probs = tf.nn.softmax(detetion_results[:, :, :, 5:])\n",
    "\n",
    "    anchors = tf.constant(anchors, dtype=tf.float32)\n",
    "\n",
    "    height_ind = tf.range(H, dtype=tf.float32)\n",
    "    width_ind = tf.range(W, dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(height_ind, width_ind)\n",
    "    x_offset = tf.reshape(x_offset, [1, -1, 1])\n",
    "    y_offset = tf.reshape(y_offset, [1, -1, 1])\n",
    "\n",
    "    # decode\n",
    "    bbox_x = (bbox_xy[:, :, :, 0] + x_offset) / W\n",
    "    bbox_y = (bbox_xy[:, :, :, 1] + y_offset) / H\n",
    "    bbox_w = bbox_wh[:, :, :, 0] * anchors[:, 0] / W * 0.5\n",
    "    bbox_h = bbox_wh[:, :, :, 1] * anchors[:, 1] / H * 0.5\n",
    "\n",
    "    bboxes = tf.stack([bbox_x - bbox_w, bbox_y - bbox_h,\n",
    "                       bbox_x + bbox_w, bbox_y + bbox_h], axis=3)\n",
    "\n",
    "    return bboxes, obj_probs, class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses.py\n",
    "\"\"\"\n",
    "Loss function for YOLOv2\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def compute_loss(predictions, targets, anchors, scales, num_classes=20, feat_sizes=(13, 13)):\n",
    "    \"\"\"\n",
    "    Compute the loss of Yolov2 for training\n",
    "    \"\"\"\n",
    "    H, W = feat_sizes\n",
    "    C = num_classes\n",
    "    B = len(anchors)\n",
    "    anchors = tf.constant(anchors, dtype=tf.float32)\n",
    "    anchors = tf.reshape(anchors, [1, 1, B, 2])\n",
    "\n",
    "    sprob, sconf, snoob, scoor = scales  # the scales for different parts\n",
    "\n",
    "    _coords = targets[\"coords\"]  # ground truth [-1, H*W, B, 4]\n",
    "    _probs = targets[\"probs\"]    # class probability [-1, H*W, B, C] one hot\n",
    "    _confs = targets[\"confs\"]    # 1 for object, 0 for background, [-1, H*W, B]\n",
    "\n",
    "    # decode the net output\n",
    "    predictions = tf.reshape(predictions, [-1, H, W, B, (5 + C)])\n",
    "    coords = predictions[:, :, :, :, 0:4]   # t_x, t_y, t_w, t_h\n",
    "    coords = tf.reshape(coords, [-1, H*W, B, 4])\n",
    "    coords_xy = tf.nn.sigmoid(coords[:, :, :, 0:2])  # (0, 1) relative cell top left\n",
    "    coords_wh = tf.sqrt(tf.exp(coords[:, :, :, 2:4]) * anchors /\n",
    "                        np.reshape([W, H], [1, 1, 1, 2])) # sqrt of w, h (0, 1)\n",
    "    coords = tf.concat([coords_xy, coords_wh], axis=3)  # [batch_size, H*W, B, 4]\n",
    "\n",
    "    confs = tf.nn.sigmoid(predictions[:, :, :, :, 4])  # object confidence\n",
    "    confs = tf.reshape(confs, [-1, H*W, B, 1])\n",
    "\n",
    "    probs = tf.nn.softmax(predictions[:, :, :, :, 5:])  # class probability\n",
    "    probs = tf.reshape(probs, [-1, H*W, B, C])\n",
    "\n",
    "    preds = tf.concat([coords, confs, probs], axis=3)  # [-1, H*W, B, (4+1+C)]\n",
    "\n",
    "    # match ground truths with anchors (predictions in fact)\n",
    "    # assign ground truths to the predictions with the best IOU (select 1 among 5 anchors)\n",
    "    wh = tf.pow(coords[:, :, :, 2:4], 2) * np.reshape([W, H], [1, 1, 1, 2])\n",
    "    areas = wh[:, :, :, 0] * wh[:, :, :, 1]\n",
    "    centers = coords[:, :, :, 0:2]\n",
    "    up_left, down_right = centers - (wh * 0.5), centers + (wh * 0.5)\n",
    "\n",
    "    # the ground truth\n",
    "    _wh = tf.pow(_coords[:, :, :, 2:4], 2) * np.reshape([W, H], [1, 1, 1, 2])\n",
    "    _areas = _wh[:, :, :, 0] * _wh[:, :, :, 1]\n",
    "    _centers = _coords[:, :, :, 0:2]\n",
    "    _up_left, _down_right = _centers - (_wh * 0.5), _centers + (_wh * 0.5)\n",
    "\n",
    "    # compute IOU\n",
    "    inter_upleft = tf.maximum(up_left, _up_left)\n",
    "    inter_downright = tf.minimum(down_right, _down_right)\n",
    "    inter_wh = tf.maximum(inter_downright - inter_upleft, 0.0)\n",
    "    intersects = inter_wh[:, :, :, 0] * inter_wh[:, :, :, 1]\n",
    "    ious = tf.truediv(intersects, areas + _areas - intersects)\n",
    "\n",
    "    best_iou_mask = tf.equal(ious, tf.reduce_max(ious, axis=2, keep_dims=True))\n",
    "    best_iou_mask = tf.cast(best_iou_mask, tf.float32)\n",
    "    mask = best_iou_mask * _confs  # [-1, H*W, B]\n",
    "    mask = tf.expand_dims(mask, -1)  # [-1, H*W, B, 1]\n",
    "\n",
    "    # compute weight terms\n",
    "    confs_w = snoob * (1 - mask) + sconf * mask\n",
    "    coords_w = scoor * mask\n",
    "    probs_w = sprob * mask\n",
    "    weights = tf.concat([coords_w, confs_w, probs_w], axis=3)\n",
    "\n",
    "    truths = tf.concat([_coords, tf.expand_dims(_confs, -1), _probs], 3)\n",
    "\n",
    "    loss = tf.pow(preds - truths, 2) * weights\n",
    "    loss = tf.reduce_sum(loss, axis=[1, 2, 3])\n",
    "    loss = 0.5 * tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "\"\"\"\n",
    "YOLOv2 implemented by Tensorflow, only for predicting\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "######## basic layers #######\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return tf.nn.leaky_relu(x, alpha=0.1, name=\"leaky_relu\")\n",
    "\n",
    "# Conv2d\n",
    "def conv2d(x, filters, size, pad=0, stride=1, batch_normalize=1,\n",
    "           activation=leaky_relu, use_bias=False, name=\"conv2d\"):\n",
    "    if pad > 0:\n",
    "        x = tf.pad(x, [[0, 0], [pad, pad], [pad, pad], [0, 0]])\n",
    "    out = tf.layers.conv2d(x, filters, size, strides=stride, padding=\"VALID\",\n",
    "                           activation=None, use_bias=use_bias, name=name)\n",
    "    if batch_normalize == 1:\n",
    "        out = tf.layers.batch_normalization(out, axis=-1, momentum=0.9,\n",
    "                                            training=False, name=name+\"_bn\")\n",
    "    if activation:\n",
    "        out = activation(out)\n",
    "    return out\n",
    "\n",
    "# maxpool2d\n",
    "def maxpool(x, size=2, stride=2, name=\"maxpool\"):\n",
    "    return tf.layers.max_pooling2d(x, size, stride)\n",
    "\n",
    "# reorg layer\n",
    "def reorg(x, stride):\n",
    "    return tf.extract_image_patches(x, [1, stride, stride, 1],\n",
    "                        [1, stride, stride, 1], [1,1,1,1], padding=\"VALID\")\n",
    "\n",
    "\n",
    "def darknet(images, n_last_channels=425):\n",
    "    \"\"\"Darknet19 for YOLOv2\"\"\"\n",
    "    net = conv2d(images, 32, 3, 1, name=\"conv1\")\n",
    "    net = maxpool(net, name=\"pool1\")\n",
    "    net = conv2d(net, 64, 3, 1, name=\"conv2\")\n",
    "    net = maxpool(net, name=\"pool2\")\n",
    "    net = conv2d(net, 128, 3, 1, name=\"conv3_1\")\n",
    "    net = conv2d(net, 64, 1, name=\"conv3_2\")\n",
    "    net = conv2d(net, 128, 3, 1, name=\"conv3_3\")\n",
    "    net = maxpool(net, name=\"pool3\")\n",
    "    net = conv2d(net, 256, 3, 1, name=\"conv4_1\")\n",
    "    net = conv2d(net, 128, 1, name=\"conv4_2\")\n",
    "    net = conv2d(net, 256, 3, 1, name=\"conv4_3\")\n",
    "    net = maxpool(net, name=\"pool4\")\n",
    "    net = conv2d(net, 512, 3, 1, name=\"conv5_1\")\n",
    "    net = conv2d(net, 256, 1, name=\"conv5_2\")\n",
    "    net = conv2d(net, 512, 3, 1, name=\"conv5_3\")\n",
    "    net = conv2d(net, 256, 1, name=\"conv5_4\")\n",
    "    net = conv2d(net, 512, 3, 1, name=\"conv5_5\")\n",
    "    shortcut = net\n",
    "    net = maxpool(net, name=\"pool5\")\n",
    "    net = conv2d(net, 1024, 3, 1, name=\"conv6_1\")\n",
    "    net = conv2d(net, 512, 1, name=\"conv6_2\")\n",
    "    net = conv2d(net, 1024, 3, 1, name=\"conv6_3\")\n",
    "    net = conv2d(net, 512, 1, name=\"conv6_4\")\n",
    "    net = conv2d(net, 1024, 3, 1, name=\"conv6_5\")\n",
    "    # ---------\n",
    "    net = conv2d(net, 1024, 3, 1, name=\"conv7_1\")\n",
    "    net = conv2d(net, 1024, 3, 1, name=\"conv7_2\")\n",
    "    # shortcut\n",
    "    shortcut = conv2d(shortcut, 64, 1, name=\"conv_shortcut\")\n",
    "    shortcut = reorg(shortcut, 2)\n",
    "    net = tf.concat([shortcut, net], axis=-1)\n",
    "    net = conv2d(net, 1024, 3, 1, name=\"conv8\")\n",
    "    # detection layer\n",
    "    net = conv2d(net, n_last_channels, 1, batch_normalize=0,\n",
    "                 activation=None, use_bias=True, name=\"conv_dec\")\n",
    "    return net\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = tf.random_normal([1, 416, 416, 3])\n",
    "    model = darknet(x)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./checkpoint_dir/yolo2_coco.ckpt\")\n",
    "        print(sess.run(model).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.py\n",
    "\"\"\"\n",
    "Help functions for YOLOv2\n",
    "\"\"\"\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "############## preprocess image ##################\n",
    "\n",
    "\n",
    "def preprocess_image(image, image_size=(416, 416)):\n",
    "    \"\"\"Preprocess a image to inference\"\"\"\n",
    "    image_cp = np.copy(image).astype(np.float32)\n",
    "    # resize the image\n",
    "    image_rgb = cv2.cvtColor(image_cp, cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(image_rgb, image_size)\n",
    "    # normalize\n",
    "    image_normalized = image_resized.astype(np.float32) / 255.0\n",
    "    # expand the batch_size dim\n",
    "    image_expanded = np.expand_dims(image_normalized, axis=0)\n",
    "    return image_expanded\n",
    "\n",
    "def postprocess(bboxes, obj_probs, class_probs, image_shape=(416, 416),\n",
    "                threshold=0.5):\n",
    "    \"\"\"post process the detection results\"\"\"\n",
    "    bboxes = np.reshape(bboxes, [-1, 4])\n",
    "    bboxes[:, 0::2] *= float(image_shape[1])\n",
    "    bboxes[:, 1::2] *= float(image_shape[0])\n",
    "    bboxes = bboxes.astype(np.int32)\n",
    "\n",
    "    # clip the bboxs\n",
    "    bbox_ref = [0, 0, image_shape[1] - 1, image_shape[0] - 1]\n",
    "    bboxes = bboxes_clip(bbox_ref, bboxes)\n",
    "\n",
    "    obj_probs = np.reshape(obj_probs, [-1])\n",
    "    class_probs = np.reshape(class_probs, [len(obj_probs), -1])\n",
    "    class_inds = np.argmax(class_probs, axis=1)\n",
    "    class_probs = class_probs[np.arange(len(obj_probs)), class_inds]\n",
    "    scores = obj_probs * class_probs\n",
    "\n",
    "    # filter bboxes with scores > threshold\n",
    "    keep_inds = scores > threshold\n",
    "    bboxes = bboxes[keep_inds]\n",
    "    scores = scores[keep_inds]\n",
    "    class_inds = class_inds[keep_inds]\n",
    "\n",
    "    # sort top K\n",
    "    class_inds, scores, bboxes = bboxes_sort(class_inds, scores, bboxes)\n",
    "    # nms\n",
    "    class_inds, scores, bboxes = bboxes_nms(class_inds, scores, bboxes)\n",
    "\n",
    "    return bboxes, scores, class_inds\n",
    "\n",
    "def draw_detection(im, bboxes, scores, cls_inds, labels, thr=0.3):\n",
    "    # for display\n",
    "    ############################\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    hsv_tuples = [(x / float(len(labels)), 1., 1.)\n",
    "                  for x in range(len(labels))]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "    # draw image\n",
    "    imgcv = np.copy(im)\n",
    "    h, w, _ = imgcv.shape\n",
    "    for i, box in enumerate(bboxes):\n",
    "        if scores[i] < thr:\n",
    "            continue\n",
    "        cls_indx = cls_inds[i]\n",
    "\n",
    "        thick = int((h + w) / 300)\n",
    "        cv2.rectangle(imgcv,\n",
    "                      (box[0], box[1]), (box[2], box[3]),\n",
    "                      colors[cls_indx], thick)\n",
    "        mess = '%s: %.3f' % (labels[cls_indx], scores[i])\n",
    "        if box[1] < 20:\n",
    "            text_loc = (box[0] + 2, box[1] + 15)\n",
    "        else:\n",
    "            text_loc = (box[0], box[1] - 10)\n",
    "        cv2.putText(imgcv, mess, text_loc,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1e-3 * h, colors[cls_indx], thick // 3)\n",
    "\n",
    "    return imgcv\n",
    "\n",
    "\n",
    "############## process bboxes ##################\n",
    "def bboxes_clip(bbox_ref, bboxes):\n",
    "    \"\"\"Clip bounding boxes with respect to reference bbox.\n",
    "    \"\"\"\n",
    "    bboxes = np.copy(bboxes)\n",
    "    bboxes = np.transpose(bboxes)\n",
    "    bbox_ref = np.transpose(bbox_ref)\n",
    "    bboxes[0] = np.maximum(bboxes[0], bbox_ref[0])\n",
    "    bboxes[1] = np.maximum(bboxes[1], bbox_ref[1])\n",
    "    bboxes[2] = np.minimum(bboxes[2], bbox_ref[2])\n",
    "    bboxes[3] = np.minimum(bboxes[3], bbox_ref[3])\n",
    "    bboxes = np.transpose(bboxes)\n",
    "    return bboxes\n",
    "\n",
    "def bboxes_sort(classes, scores, bboxes, top_k=400):\n",
    "    \"\"\"Sort bounding boxes by decreasing order and keep only the top_k\n",
    "    \"\"\"\n",
    "    # if priority_inside:\n",
    "    #     inside = (bboxes[:, 0] > margin) & (bboxes[:, 1] > margin) & \\\n",
    "    #         (bboxes[:, 2] < 1-margin) & (bboxes[:, 3] < 1-margin)\n",
    "    #     idxes = np.argsort(-scores)\n",
    "    #     inside = inside[idxes]\n",
    "    #     idxes = np.concatenate([idxes[inside], idxes[~inside]])\n",
    "    idxes = np.argsort(-scores)\n",
    "    classes = classes[idxes][:top_k]\n",
    "    scores = scores[idxes][:top_k]\n",
    "    bboxes = bboxes[idxes][:top_k]\n",
    "    return classes, scores, bboxes\n",
    "\n",
    "def bboxes_iou(bboxes1, bboxes2):\n",
    "    \"\"\"Computing iou between bboxes1 and bboxes2.\n",
    "    Note: bboxes1 and bboxes2 can be multi-dimensional, but should broacastable.\n",
    "    \"\"\"\n",
    "    bboxes1 = np.transpose(bboxes1)\n",
    "    bboxes2 = np.transpose(bboxes2)\n",
    "    # Intersection bbox and volume.\n",
    "    int_ymin = np.maximum(bboxes1[0], bboxes2[0])\n",
    "    int_xmin = np.maximum(bboxes1[1], bboxes2[1])\n",
    "    int_ymax = np.minimum(bboxes1[2], bboxes2[2])\n",
    "    int_xmax = np.minimum(bboxes1[3], bboxes2[3])\n",
    "\n",
    "    int_h = np.maximum(int_ymax - int_ymin, 0.)\n",
    "    int_w = np.maximum(int_xmax - int_xmin, 0.)\n",
    "    int_vol = int_h * int_w\n",
    "    # Union volume.\n",
    "    vol1 = (bboxes1[2] - bboxes1[0]) * (bboxes1[3] - bboxes1[1])\n",
    "    vol2 = (bboxes2[2] - bboxes2[0]) * (bboxes2[3] - bboxes2[1])\n",
    "    iou = int_vol / (vol1 + vol2 - int_vol)\n",
    "    return iou\n",
    "\n",
    "def bboxes_nms(classes, scores, bboxes, nms_threshold=0.5):\n",
    "    \"\"\"Apply non-maximum selection to bounding boxes.\n",
    "    \"\"\"\n",
    "    keep_bboxes = np.ones(scores.shape, dtype=np.bool)\n",
    "    for i in range(scores.size-1):\n",
    "        if keep_bboxes[i]:\n",
    "            # Computer overlap with bboxes which are following.\n",
    "            overlap = bboxes_iou(bboxes[i], bboxes[(i+1):])\n",
    "            # Overlap threshold for keeping + checking part of the same class\n",
    "            keep_overlap = np.logical_or(overlap < nms_threshold, classes[(i+1):] != classes[i])\n",
    "            keep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):], keep_overlap)\n",
    "\n",
    "    idxes = np.where(keep_bboxes)\n",
    "    return classes[idxes], scores[idxes], bboxes[idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
